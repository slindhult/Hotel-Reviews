{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV, cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from: https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Hotel_Reviews.csv')\n",
    "\n",
    "# remove rows with no reviews\n",
    "data = data[(data['Negative_Review'] != 'No Negative') | (data['Positive_Review'] != 'No Positive')]\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many unqiue in each column\n",
    "#for i in data.columns:\n",
    "#    print(i, len(data[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns\n",
    "data.drop(['Hotel_Name','Hotel_Address','Review_Date','days_since_review'],  axis=1, inplace=True)\n",
    "data['Average_Score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark - error if you always guessed the average (1.18)\n",
    "mean_absolute_error(data['Average_Score'], data['Reviewer_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting tags from 55,000 to a few - started as a list of strings that looked like lists of strings\n",
    "#tags = data.Tags\n",
    "\n",
    "#import ast\n",
    "#new_tags = []\n",
    "#for i in tags:\n",
    "#    new_tags.append(ast.literal_eval(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check most common tags\n",
    "from collections import Counter\n",
    "list_for_counting = []\n",
    "for i in new_tags:\n",
    "    for t in i:\n",
    "        list_for_counting.append(t)\n",
    "    \n",
    "c = Counter(list_for_counting)\n",
    "c.most_common(20)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# feature engineering tags to reduce columns\n",
    "for index, i in enumerate(new_tags):\n",
    "    for idx, t in enumerate(i):\n",
    "        if t not in ['Stayed 1-2 nights','Stayed 3-4 nights', 'Stayed 5+ nights', 'Fancy', 'Budget', 'Medium', 'High', ' Business trip ', ' Solo traveler ', ' Leisure trip ', ' Couple ', ' Group ', ' Family with young children ', ' Family with older children ']:\n",
    "            if t in [' Stayed 1 night ',' Stayed 2 nights ']:\n",
    "                new_tags[index][idx] = 'Stayed 1-2 nights'\n",
    "            if t in [' Stayed 3 nights ',' Stayed 4 nights ']:\n",
    "                new_tags[index][idx] = 'Stayed 3-4 nights'\n",
    "            if t in [' Stayed 5 nights ',' Stayed 6 nights ', ' Stayed 7 nights ', ' Stayed 8 nights ', ' Stayed 9 nights ', ' Stayed 10 nights ',  ' Stayed 11 nights ',\n",
    "                 ' Stayed 12 nights ', ' Stayed 13 nights ', ' Stayed 14 nights ', ' Stayed 15 nights ', ' Stayed 16 nights ', ' Stayed 17 nights ',' Stayed 18 nights ', ' Stayed 19 nights ', ' Stayed 20 nights ',\n",
    "                 ' Stayed 21 nights ', ' Stayed 22 nights ', ' Stayed 23 nights ', ' Stayed 24 nights ', ' Stayed 25 nights ', ' Stayed 26 nights ',\n",
    "                 ' Stayed 27 nights ', ' Stayed 28 nights ', ' Stayed 29 nights ', ' Stayed 30 nights ', ' Stayed 31 nights ',]:\n",
    "                new_tags[index][idx] = 'Stayed 5+ nights'\n",
    "            if 'Luxury' in t or 'VIP' in t or 'Executive' in t or 'Ambassador' in t or 'Royal' in t or 'Penthouse' in t or 'Suite' in t or 'Duplex' in t or 'Presidential' in t or 'Apartment' in t or 'Apartement' in t:\n",
    "                new_tags[index][idx] = 'Fancy'\n",
    "            if 'Superior' in t or 'Premium' in t or 'Prestige' in t or 'Premiere' in t or 'Privilege' in t or 'Deluxe' in t or 'Premier' in t or 'Club' in t or 'View' in t or 'Art' in t or 'Fabulous' in t or 'Wonderful' in t or 'Loft' in t or 'Eiffel' in t or 'Spa' in t or 'King' in t:\n",
    "                new_tags[index][idx] = 'High'\n",
    "            if 'Standard' in t or 'Budget' in t or 'Small' in t or 'Economy' in t or 'Basic' in t or 'Bunk Bed' in t or 'Interior' in t or 'Special Offer' in t or 'Triple' in t or 'Quadruple' in t or 'Quintuple' in t or 'Sextuple' in t or 'Junior' in t or 'Twin' in t or 'Mini' in t or 'Check In' in t or 'Check in' in t or'Solo' in t or 'Camper' in t or 'Rooms' in t or 'Interconnecting' in t or 'FAMILY' in t or 'Atrium' in t or 'rooms' in t:\n",
    "                new_tags[index][idx] = 'Budget'\n",
    "            if 'Comfort' in t or 'Family' in t or 'Classic' in t or 'Large' in t or 'Double' in t or 'Cosy' in t or 'Single' in t or 'Connecting' in t or 'Queen' in t or 'Cozy' in t or 'Studio' in t or 'Adjacent' in t or 'Two' in t:\n",
    "                new_tags[index][idx] = 'Medium'\n",
    "            \n",
    "for index, i in enumerate(new_tags):\n",
    "    for idx, t in enumerate(i):            \n",
    "            if t not in ['Stayed 1-2 nights','Stayed 3-4 nights', 'Stayed 5+ nights', 'Fancy', 'Budget', 'Medium', 'High', ' Business trip ', ' Solo traveler ', ' Leisure trip ', ' Couple ', ' Group ', ' Family with young children ', ' Family with older children ']:\n",
    "                   new_tags[index][idx] = 'High'\n",
    "            \n",
    "#tags_final = []\n",
    "#for index, i in enumerate(new_tags):\n",
    "#    new = []\n",
    "#    for idx, t in enumerate(i):\n",
    "#        if t in ['Stayed 1-2 nights','Stayed 3-4 nights', 'Suite', 'Apartment', 'Fancy', 'Budget', 'Medium', 'High', ' Business Trip ', ' Solo Traveler ', ' Leisure trip ', ' Couple ', ' Group ', ' Family with young children ', ' Family with older children ']:\n",
    "#            new.append(i[idx])\n",
    "#    tags_final.append(new)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = []\n",
    "for i in new_tags:\n",
    "    for t in i:\n",
    "        if t not in unique_tags:\n",
    "            unique_tags.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace tags with feature engineered tags\n",
    "data['New_Tags'] = new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onehotencode tags and drop unneeded columns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "tagdf = pd.DataFrame(mlb.fit_transform(data.New_Tags),columns=mlb.classes_, index=data.index)\n",
    "\n",
    "\n",
    "data = data.join(tagdf)\n",
    "data = data.drop(['New_Tags'], axis=1)\n",
    "data.drop('Tags', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = data.pop('Negative_Review')\n",
    "pos = data.pop('Positive_Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't end up using nationality\n",
    "#nat = pd.get_dummies(data['Reviewer_Nationality'], prefix='Nationality: ')\n",
    "#nat = nat.astype(int)\n",
    "#data = data.join(nat)\n",
    "#data = data.drop(['Reviewer_Nationality'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = data.pop('lat')\n",
    "lng = data.pop('lng')\n",
    "data = data.drop(['Reviewer_Nationality'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean = clean.to_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords and lemmatize reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "data['Neg_Review_Clean'] = data['Negative_Review']\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered = []\n",
    "for i in data['Neg_Review_Clean']:\n",
    "    i = i.split()\n",
    "    filtered_sentence = [lem.lemmatize(w.lower()) for w in i if w not in stop_words]\n",
    "    filtered.append(' '.join(filtered_sentence))\n",
    "    \n",
    "cleanest['Neg_Review_Clean'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords and lemmatize reviews\n",
    "data['Pos_Review_Clean'] = data['Positive_Review']\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filteredpos = []\n",
    "for i in data['Pos_Review_Clean']:\n",
    "    i = i.split()\n",
    "    filtered_sentence = [lem.lemmatize(w) for w in i if w not in stop_words]\n",
    "    filteredpos.append(' '.join(filtered_sentence))\n",
    "    \n",
    "cleanest['Pos_Review_Clean'] = filteredpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = cleanest['Neg_Review_Clean']\n",
    "pos = cleanest['Pos_Review_Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "neg_review_sentiment = []\n",
    "for i in neg:\n",
    "    review = TextBlob(i)\n",
    "    neg_review_sentiment.append(review.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_review_sentiments = [i.polarity for i in neg_review_sentiment]\n",
    "cleanest['neg_review_sentiment'] = neg_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_sentiment = []\n",
    "for i in pos:\n",
    "    review = TextBlob(i)\n",
    "    pos_review_sentiment.append(review.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_sentiments = [i.polarity for i in pos_review_sentiment]\n",
    "cleanest['pos_review_sentiment'] = pos_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanest.to_csv('cleanest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmed = data.to_csv('lemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest = pd.read_csv('cleanest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Neg_Review_Clean', 'Pos_Review_Clean'], axis=1, inplace=True)\n",
    "y = cleanest.pop('Reviewer_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negdf = vader[(vader['neg_sent']<-.95) & (vader['pos_sent']<-.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = data.loc[data['neg_review_sentiment']==-1]\n",
    "posnegative = data.loc[data['pos_review_sentiment']==-1]\n",
    "\n",
    "\n",
    "posnegative = data.loc[data['neg_review_sentiment']==1]\n",
    "positive = data.loc[data['pos_review_sentiment']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1 neg ',data.loc[5838]['Negative_Review'])\n",
    "print(data.loc[5838]['Positive_Review'])\n",
    "print(data.loc[137862]['Negative_Review'])\n",
    "print(data.loc[137862]['Positive_Review'])\n",
    "print(data.loc[221918]['Negative_Review'])\n",
    "print(data.loc[221918]['Positive_Review'])\n",
    "print(data.loc[393760]['Negative_Review'])\n",
    "print(data.loc[393760]['Positive_Review'])\n",
    "print(data.loc[464189]['Negative_Review'])\n",
    "print(data.loc[464189]['Positive_Review'])\n",
    "print(data.loc[502957]['Negative_Review'])\n",
    "print(data.loc[502957]['Positive_Review'])\n",
    "print(data.loc[509441]['Negative_Review'])\n",
    "print(data.loc[509441]['Positive_Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdf = vader[(vader['neg_sent']>.99) & (vader['pos_sent']>.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive[positive['neg_review_sentiment']==1].sort_values('Reviewer_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[79198]['Negative_Review'])\n",
    "print(data.loc[79198]['Positive_Review'])\n",
    "print(data.loc[88327]['Negative_Review'])\n",
    "print(data.loc[88327]['Positive_Review'])\n",
    "print(data.loc[102118]['Negative_Review'])\n",
    "print(data.loc[102118]['Positive_Review'])\n",
    "print(data.loc[177909]['Negative_Review'])\n",
    "print(data.loc[177909]['Positive_Review'])\n",
    "print(data.loc[186402]['Negative_Review'])\n",
    "print(data.loc[186402]['Positive_Review'])\n",
    "print(data.loc[187132]['Negative_Review'])\n",
    "print(data.loc[187132]['Positive_Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.drop(['Negative_Review', 'Positive_Review', 'Neg_Review_Clean', 'Pos_Review_Clean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling = modeling.to_csv('modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = pd.read_csv('modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeling.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "y = modeling.pop('Reviewer_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modeling.drop('days_since_review', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleanest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('clean.csv')\n",
    "y = clean.pop('Reviewer_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.drop(['Unnamed: 0.1','Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#END CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = modeling.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale select columns\n",
    "cols_to_scale = ['Additional_Number_of_Scoring', 'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
    "       'Review_Total_Positive_Word_Counts',\n",
    "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'neg_review_sentiment', 'pos_review_sentiment']\n",
    "\n",
    "scaled[cols_to_scale] = scaler.fit_transform(scaled[cols_to_scale])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaleddf = scaled.to_csv('scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = pd.read_csv('scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "y = data.pop('Reviewer_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(min_samples_leaf = 30,\n",
    "                          max_depth=25,\n",
    "                          max_features=10,\n",
    "                          n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr = GradientBoostingRegressor(learning_rate=0.01,\n",
    "                                  loss='ls',\n",
    "                                 max_depth=15,\n",
    "                                  n_estimators=100,\n",
    "                                 min_samples_leaf=120,\n",
    "                                 max_features=10,\n",
    "                                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = gdbr.predict(X_test)\n",
    "mean_absolute_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "param_dist = dict(min_samples_leaf = [5,10,15,20],\n",
    "                          max_depth = [5,10,20,30],\n",
    "                          max_features=[3,5,10,15, 20],\n",
    "                          n_estimators=[50,75,100,300,500])\n",
    "rand2 = RandomizedSearchCV(rf, param_dist, cv=10, scoring='neg_mean_absolute_error', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "pprint(rand2.best_estimator_.get_params())\n",
    "\n",
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'mse',\n",
    " 'max_depth': 30,\n",
    " 'max_features': 40,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 500,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Best random forest results\n",
    "RandomizedSearchCV(cv=10, error_score=nan,\n",
    "                   estimator=RandomForestRegressor(bootstrap=True,\n",
    "                                                   ccp_alpha=0.0,\n",
    "                                                   criterion='mse',\n",
    "                                                   max_depth=25,\n",
    "                                                   max_features=10,\n",
    "                                                   max_leaf_nodes=None,\n",
    "                                                   max_samples=None,\n",
    "                                                   min_impurity_decrease=0.0,\n",
    "                                                   min_impurity_split=None,\n",
    "                                                   min_samples_leaf=30,\n",
    "                                                   min_samples_split=2,\n",
    "                                                   min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=500,\n",
    "                                                   n_jobs=None, oob_score=False,\n",
    "                                                   ra...rbose=0,\n",
    "                                                   warm_start=False),\n",
    "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
    "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
    "                                        'max_features': [10, 20, 30, 40, 50],\n",
    "                                        'min_samples_leaf': [5, 10, 15, 20, 30,\n",
    "                                                             50],\n",
    "                                        'n_estimators': [50, 75, 100, 300, 500,\n",
    "                                                         1000]},\n",
    "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrand2 = rand2.predict(X_test)\n",
    "mean_absolute_error(y_test, yrand2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cleanest\n",
    "rand2.best_estimator_.get_params\n",
    "\n",
    "<bound method BaseEstimator.get_params of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=20, max_features=15, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=10,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(min_samples_leaf = 5,\n",
    "                          max_depth = 30,\n",
    "                          max_features=5,\n",
    "                          n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.88\n",
    "yrand2 = rf.predict(X_test)\n",
    "mean_absolute_error(y_test, yrand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,yrand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = rf.feature_importances_\n",
    "columns = vader.columns\n",
    "zipped = zip(columns, feats)\n",
    "top_feats = sorted(zipped, key = lambda x: x[1], reverse=True)\n",
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = sorted(zipped, key = lambda x: x[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount = pd.read_csv('vadercount2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'Unnamed: 0.1.1.1.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv = vadercount\n",
    "y = y['Reviewer_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv_train, Xv_test, yv_train, yv_test = train_test_split(Xv,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "param_dist = dict(min_samples_leaf = [5,10,15,20],\n",
    "                          max_depth = [5,10,20,30],\n",
    "                          max_features=[3,5,10,15, 20],\n",
    "                          n_estimators=[50,75,100,300,500])\n",
    "rand2 = RandomizedSearchCV(rf, param_dist, cv=10, scoring='neg_mean_absolute_error', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.fit(Xv_train, yv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8644864926810877\n",
    "yvadersearch = rand2.predict(Xv_test)\n",
    "mean_absolute_error(yv_test, yvadersearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Best rf\n",
    "rand2.best_estimator_.get_params\n",
    "<bound method BaseEstimator.get_params of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=20, max_features=15, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=10,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = rf.feature_importances_\n",
    "cols = scaled.columns\n",
    "zipped = zip(cols, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr = GradientBoostingRegressor(learning_rate=0.01,\n",
    "                                  loss='ls',\n",
    "                                 max_depth=15,\n",
    "                                  n_estimators=100,\n",
    "                                 min_samples_leaf=120,\n",
    "                                 max_features=10,\n",
    "                                  random_state=1)\n",
    "\n",
    "gdbr.fit(Xv_train, yv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.867067557566572\n",
    "ygvader = rf.predict(Xv_test)\n",
    "mean_absolute_error(yv_test, ygvader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr = GradientBoostingRegressor()\n",
    "param_dist = dict(min_samples_leaf = [10,15,20,30,50],\n",
    "                          max_depth = [5,10,20,30],\n",
    "                          max_features=[10, 20, 30],\n",
    "                          n_estimators=[50,100,300,500],\n",
    "                         learning_rate = [0.1, .05, 0.07, 0.01])\n",
    "booster2 = RandomizedSearchCV(gdbr, param_dist, cv=10, scoring='neg_mean_absolute_error', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV(cv=10, error_score=nan,\n",
    "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
    "                                                       criterion='friedman_mse',\n",
    "                                                       init=None,\n",
    "                                                       learning_rate=0.01,\n",
    "                                                       loss='ls', max_depth=15,\n",
    "                                                       max_features=10,\n",
    "                                                       max_leaf_nodes=None,\n",
    "                                                       min_impurity_decrease=0.0,\n",
    "                                                       min_impurity_split=None,\n",
    "                                                       min_samples_leaf=120,\n",
    "                                                       min_samples_split=2,\n",
    "                                                       min_weight_fraction_leaf=0.0,\n",
    "                                                       n_estimators=100...\n",
    "                                                       warm_start=False),\n",
    "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
    "                   param_distributions={'learning_rate': [0.1, 0.05, 0.07,\n",
    "                                                          0.01],\n",
    "                                        'max_depth': [5, 10, 20, 30],\n",
    "                                        'max_features': [10, 20, 30, 40],\n",
    "                                        'min_samples_leaf': [10, 15, 20, 30,\n",
    "                                                             50],\n",
    "                                        'n_estimators': [50, 100, 300, 500,\n",
    "                                                         1000]},\n",
    "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yboost2 = booster2.predict(X_test)\n",
    "mean_absolute_error(y_test, yboost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdbr = GradientBoostingRegressor(max_depth=30, max_leaf_nodes=40, min_samples_leaf=50, n_estimators=100)\n",
    "\n",
    "gdbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yboost2 = gdbr.predict(X_test)\n",
    "mean_absolute_error(y_test, yboost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_feats = gdbr.feature_importances_\n",
    "columnss = modeling.columns\n",
    "zipped = zip(columnss, boost_feats)\n",
    "top_feats = sorted(zipped, key = lambda x: x[1], reverse=True)\n",
    "top_feats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Best gradient boost score\n",
    "from pprint import pprint\n",
    "pprint(booster2.best_estimator_.get_params())\n",
    "{'alpha': 0.9,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'friedman_mse',\n",
    " 'init': None,\n",
    " 'learning_rate': 0.1,\n",
    " 'loss': 'ls',\n",
    " 'max_depth': 30,\n",
    " 'max_features': 40,\n",
    " 'max_leaf_nodes': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 50,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_iter_no_change': None,\n",
    " 'presort': 'deprecated',\n",
    " 'random_state': None,\n",
    " 'subsample': 1.0,\n",
    " 'tol': 0.0001,\n",
    " 'validation_fraction': 0.1,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_of_model = y_test-yboost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Largest Guess over\n",
    "range_of_model.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lowest Guess Below\n",
    "range_of_model.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(range_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(Xv_train, label=yv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_test = xgb.DMatrix(Xv_test, label=yv_test)\n",
    "param = {}\n",
    "# I used gamma regression \n",
    "param['objective'] = 'reg:gamma'\n",
    "param['eta'] = 0.05\n",
    "param['max_depth'] = 9\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 4\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "pred = bst.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Error\n",
    "error = pred - yv_test\n",
    "error = abs(error)\n",
    "error_rate = np.mean(error)/np.mean(yv_test)\n",
    "print(\"error rate = %f \" %error_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vader .811\n",
    "mean_absolute_error(yv_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''best:\n",
    "xg_test = xgb.DMatrix(Xv_test, label=yv_test)\n",
    "param = {}\n",
    "# I used gamma regression \n",
    "param['objective'] = 'reg:gamma'\n",
    "param['eta'] = 0.05\n",
    "param['max_depth'] = 9\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 4\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dict = bst.get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = feats_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(feats_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing without average score\n",
    "sans_average = clean\n",
    "sans_average.drop('Average_Score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XA_train, XA_test, y2_train, y2_test = train_test_split(sans_average, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdbr2 = GradientBoostingRegressor(max_depth=30, max_leaf_nodes=40, min_samples_leaf=50, n_estimators=100)\n",
    "\n",
    "gdbr2.fit(XA_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yboost2A = gdbr2.predict(XA_test)\n",
    "mean_absolute_error(y_test, yboost2A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, yboost2A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews[5245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = {}\n",
    "for i in negative_reviews:\n",
    "    try:\n",
    "        for w in i.split():\n",
    "            if w not in negative_words.keys():\n",
    "                negative_words[w] = 0\n",
    "            negative_words[w] +=1\n",
    "    except AttributeError:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_list = sorted(negative_words.values())[::-1][:30]\n",
    "for k,v in negative_words.items():\n",
    "    if v in top_list:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = {}\n",
    "for i in positive_reviews:\n",
    "    try:\n",
    "        for w in i.split():\n",
    "            if w not in positive_words.keys():\n",
    "                positive_words[w] = 0\n",
    "            positive_words[w] +=1\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_list = sorted(negative_words.values())[::-1][:30]\n",
    "for k,v in negative_words.items():\n",
    "    if v in top_list:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Reviewer_Nationality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europe = pd.read_html('https://en.wikipedia.org/wiki/Ethnic_groups_in_Europe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro = list(europe[4]['Country']\n",
    "for idx, i in enumerate(euro):\n",
    "    if not i.isalpha():\n",
    "        euro[idx] = i[:-3]\n",
    "    if i =='United King':\n",
    "        euro[idx] = 'United Kingdom'\n",
    "euro[6] = 'Bosnia and Herzegovina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviewer_Nationality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euro_or_no = list(data['Reviewer_Nationality'])\n",
    "#for idx, i in enumerate(euro_or_no):\n",
    "#    euro_or_no[idx] = i[1:-1]\n",
    "for idx,i in enumerate(euro_or_no):\n",
    "\n",
    "    if i in list(euro):\n",
    "        euro_or_no[idx] = 'European'\n",
    "    else:\n",
    "        euro_or_no[idx] = 'Not European'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_or_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviewer_Nationality'] = euro_or_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euros = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euros.drop(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
    "        'Hotel_Name',\n",
    "       'Negative_Review', \n",
    "       'Total_Number_of_Reviews', 'Positive_Review',\n",
    "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Tags',\n",
    "       'days_since_review', 'lat', 'lng'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euros.Reviewer_Nationality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euros.groupby('Reviewer_Nationality').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negrevs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmed = pd.read_csv('lemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_content = lemmed['Neg_Review_Clean']\n",
    "pos_content = lemmed['Pos_Review_Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(neg_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ngrams 2,2\n",
    "count = CountVectorizer(max_features=1000, stop_words='english', ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg = count.fit_transform(lemmed['Neg_Review_Clean'].values.astype('U')) \n",
    "fitted_pos = count.fit_transform(lemmed['Pos_Review_Clean'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_pos = tfidf.fit_transform(lemmed['Pos_Review_Clean'].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_neg = tfidf.fit_transform(lemmed['Neg_Review_Clean'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pos = tfidf_pos.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_neg.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(max_features=300, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pos = count.fit_transform(lemmed['Pos_Review_Clean'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_col_names = count.get_feature_names()\n",
    "fitted_pos = fitted_pos.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pos = pd.DataFrame(fitted_pos, columns = pos_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3 = pd.read_csv('vader3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3 = vader3.join(fitted_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3.to_csv('vadercount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount = pd.read_csv('vadercount2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg = count.fit_transform(lemmed['Neg_Review_Clean'].values.astype('U'))\n",
    "neg_col_names = count.get_feature_names()\n",
    "fitted_neg = fitted_neg.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg = pd.DataFrame(fitted_neg, columns = neg_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg = fitted_neg.add_suffix('_neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg = pd.read_csv('fittedneg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg.to_csv('fittedneg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount = vadercount.join(fitted_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount.to_csv('vadercountfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3.to_csv('vadercount2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadercount = pd.read('vadercount2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=5, init='random', random_state=0)\n",
    "W = model.fit_transform(fitted_neg)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "def fit_nmf(r):\n",
    "    nmf = NMF(n_components=r)\n",
    "    nmf.fit(fitted_neg)\n",
    "    W = nmf.transform(fitted_neg)\n",
    "    H = nmf.components_\n",
    "    return nmf.reconstruction_err_\n",
    "\n",
    "\n",
    "fit_nmf(10)\n",
    "error = [fit_nmf(i) for i in range(1,11)]\n",
    "plt.plot(range(1,11), error)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Reconstruction Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = count2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nmf_pos(r):\n",
    "    nmf = NMF(n_components=r)\n",
    "    nmf.fit(fitted_pos)\n",
    "    W = nmf.transform(fitted_pos)\n",
    "    H = nmf.components_\n",
    "    return nmf.reconstruction_err_\n",
    "\n",
    "fit_nmf_pos(8)\n",
    "error = [fit_nmf(i) for i in range(1,10)]\n",
    "plt.plot(range(1,10), error)\n",
    "plt.xticks(range(1, 10))\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Reconstruction Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count3 = CountVectorizer(max_features=1000, stop_words='english', ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words3 = count3.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_neg3 = count3.fit_transform(neg_content.values.astype('U')) \n",
    "fitted_pos3 = count3.fit_transform(pos_content.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=20, init='random', random_state=0)\n",
    "W = model.fit_transform(fitted_neg3)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated = []\n",
    "for i in H:\n",
    "    associated.append((np.argsort(i)[::-1][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for num, i in enumerate(associated):\n",
    "    lst = []\n",
    "    for idx in i:\n",
    "        lst.append(words3[idx])\n",
    "    topics.append(lst)\n",
    "    print(f'topic{num+1} :', lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=3, init='random', random_state=0)\n",
    "W = model.fit_transform(fitted_neg)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated = []\n",
    "for i in H:\n",
    "    associated.append((np.argsort(i)[::-1][:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for num, i in enumerate(associated):\n",
    "    lst = []\n",
    "    for idx in i:\n",
    "        lst.append(words[idx])\n",
    "    topics.append(lst)\n",
    "    print(f'topic{num+1} :', lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=20, init='random', random_state=0)\n",
    "W = model.fit_transform(fitted_neg)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated = []\n",
    "for i in H:\n",
    "    associated.append((np.argsort(i)[::-1][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "for num, i in enumerate(associated):\n",
    "    lst = []\n",
    "    for idx in i:\n",
    "        lst.append(words[idx])\n",
    "    topics.append(lst)\n",
    "    print(f'topic{num+1} :', lst)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=3, init='random', random_state=0)\n",
    "W2 = model.fit_transform(fitted_neg)\n",
    "H2 = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated_pos = []\n",
    "for i in H2:\n",
    "    associated_pos.append((np.argsort(i)[::-1][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pos = []\n",
    "for num, i in enumerate(associated_pos):\n",
    "    lst = []\n",
    "    for idx in i:\n",
    "        lst.append(words[idx])\n",
    "    topics_pos.append(lst)\n",
    "    print(f'topic{num+1} :', lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "data['Neg_Review_Clean'] = data['Negative_Review']\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered = []\n",
    "for i in data['Neg_Review_Clean'][:2]:\n",
    "    i = i.split()\n",
    "    filtered_sentence = [lem.lemmatize(w) for w in i if w not in stop_words]\n",
    "    filtered.append(' '.join(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Neg_Review_Clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiltered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "d = TextBlob(\"didn't\")\n",
    "d.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = TextBlob(filtered[0])\n",
    "c.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_label_topics(H, vocabulary):\n",
    "    '''\n",
    "    Print the most influential words of each latent topic, and prompt the user\n",
    "    to label each topic. The user should use their humanness to figure out what\n",
    "    each latent topic is capturing.\n",
    "    '''\n",
    "    hand_labels = []\n",
    "    for i, row in enumerate(H):\n",
    "        top_five = np.argsort(row)[::-1][:20]\n",
    "        print('topic', i)\n",
    "        print('-->', ' '.join(vocabulary[top_five]))\n",
    "        label = input('please label this topic: ')\n",
    "        hand_labels.append(label)\n",
    "        print()\n",
    "    return hand_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_labels = hand_label_topics(topics_pos, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Clouds\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [40, 10]\n",
    "\n",
    "# Create subplots for each Topic\n",
    "for index, topic in enumerate(topics):\n",
    "    wc = WordCloud(width = 1000, height = 500).generate(' '.join(topic))\n",
    "    \n",
    "    plt.subplot(2, 5, index+1)\n",
    "    plt.imshow(wc, interpolation=\"quadric\")\n",
    "    plt.axis(\"off\")\n",
    "    #plt.title(hand_labels[index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 25,\n",
    "        max_font_size = 30, \n",
    "        scale = 3,\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize = (10, 10))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "    \n",
    "# print wordcloud\n",
    "show_wordcloud(topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(topics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(topics[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(fitted_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking monthly trend, consistent scoring\n",
    "monthdf = data[['Review_Date','Average_Score','Reviewer_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf['Review_Date'] = pd.to_datetime(monthdf['Review_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf['Review_Date'] = monthdf['Review_Date'].apply(lambda x: x.strftime('%Y-%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf['City'] = city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = monthdf.groupby(['Review_Date', 'City']).agg({'Average_Score':'mean', 'Reviewer_Score':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf.sort_values('City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping\n",
    "mapdf = data[['Hotel_Name', 'Average_Score', 'lat', 'lng']]\n",
    "mapdf = mapdf.groupby(['Hotel_Name']).agg({'Average_Score':'mean', 'lat':'mean', 'lng':'mean'})\n",
    "mapdf = mapdf.dropna()\n",
    "mapdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdf['color'] = pd.cut(mapdf['Average_Score'], bins=[0,8.1,8.5,8.9,10], \n",
    "                              labels=['red', 'orange', 'blue', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "m = folium.Map(location=[52.360576, 4.915968])\n",
    "\n",
    "for i in range(mapdf.shape[0]):\n",
    "    folium.CircleMarker([mapdf['lat'][i],mapdf['lng'][i]], radius=2,tooltip=f'{mapdf[\"Hotel_Name\"][i]} : {mapdf[\"Average_Score\"][i]:0.2}', color=mapdf['color'][i]).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdf[mapdf['color']=='green'].sort_values('Average_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import FloatImage\n",
    "\n",
    "\n",
    "import folium\n",
    "b = folium.Map(location=[52.360576, 4.915968])\n",
    "# convert to (n, 2) nd-array format for heatmap\n",
    "import folium.plugins as plugins\n",
    "lat = np.array(mapdf['lat'])\n",
    "lng = np.array(mapdf['lng'])\n",
    "coords = []\n",
    "for i,j in zip(lat,lng):\n",
    "    coords.append((i,j))\n",
    "hotels = np.array(coords)\n",
    "\n",
    "\n",
    "'''steps = 20\n",
    "color_map=cm.linear.BuGrYlRd.scale(0,1).to_step(steps)\n",
    "\n",
    "gradient_map=defaultdict(dict)\n",
    "for i in range(steps):\n",
    "    gradient_map[1/steps*i] = color_map.rgb_hex_str(1/steps*i)'''\n",
    "\n",
    "\n",
    "\n",
    "image_file='legend.png'\n",
    "\n",
    "FloatImage(image_file,bottom=5,left=5).add_to(b)\n",
    "\n",
    "# plot heatmap\n",
    "for i in range(mapdf.shape[0]):\n",
    "    folium.CircleMarker([mapdf['lat'][i],mapdf['lng'][i]], radius=2, tooltip=f'{mapdf[\"Hotel_Name\"][i]} : {mapdf[\"Average_Score\"][i]:0.2}', color=mapdf['color'][i]).add_to(b)\n",
    "\n",
    "\n",
    "b.add_children(plugins.HeatMap(hotels, radius=30))\n",
    "b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdata = np.array(mapdf[['lat', 'lng','Average_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_dict={}\n",
    "for ind_val, c in zip(mapdf.index, mapdf.color):\n",
    "    # Create gradient dictionary for heatmap on the fly\n",
    "    gradient_dict[ind_val] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "hmap = folium.Map(location=[52.360576, 4.915968],control_scale = True, zoom_start=13)\n",
    "\n",
    "hmap.add_child(HeatMap(mapdata, radius = 50, gradient={.25: 'red', .5: 'orange', .75: 'blue', .89: 'green'}))\n",
    "hmap.caption = 'Test'\n",
    "hmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank dictionary of values\n",
    "# Take in reviews\n",
    "# Remove Stop words and Lemmatize\n",
    "# tfidf neg words\n",
    "# tfidf pos words\n",
    "# tfidf pos - tfidf neg\n",
    "# tfidf ngrams\n",
    "# get range\n",
    "# some small range=0\n",
    "# normalize values from - to -1 based on * rating above or below\n",
    "# normalize values from + to 1\n",
    "# add values to dictionary\n",
    "# dictionary of values\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "tfidf_pos = count.fit_transform(pos_content.values.astype('U'))\n",
    "tfidf_neg = count.fit_transform(neg_content.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(snt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sentiment_scores('If I had to choose something it would be that the nice big bed was covered by two single quilts rather than a double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = analyser.lexicon.keys()\n",
    "b = analyser.lexicon.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_lexicon = {k:v for k,v in zip(a,b)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_lexicon['small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snt = analyser.polarity_scores('No Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snt['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Negative_Review\"] = data[\"Negative_Review\"].apply(lambda x: str(x).replace(\"No Negative\", \"\"))\n",
    "data[\"Positive_Review\"] = data[\"Positive_Review\"].apply(lambda x: str(x).replace(\"No Positive\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = data['Negative_Review']\n",
    "neg_review_sentiment = []\n",
    "for i in neg:\n",
    "    snt = analyser.polarity_scores(i)\n",
    "    neg_review_sentiment.append(snt['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = data['Positive_Review']\n",
    "pos_review_sentiment = []\n",
    "for i in pos:\n",
    "    snt = analyser.polarity_scores(i)\n",
    "    pos_review_sentiment.append(snt['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest = pd.read_csv('cleanest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest[\"Neg_Review_Clean\"] = cleanest[\"Neg_Review_Clean\"].apply(lambda x: str(x).replace(\"No Negative\", \"\"))\n",
    "cleanest[\"Pos_Review_Clean\"] = cleanest[\"Pos_Review_Clean\"].apply(lambda x: str(x).replace(\"No Positive\", \"\"))\n",
    "                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = cleanest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vader.drop(['neg_review_sentiment', 'pos_review_sentiment'], axis=1, inplace=True)\n",
    "\n",
    "vader['pos_sent'] = pos_review_sentiment\n",
    "vader['neg_sent'] = neg_review_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.drop(['Unnamed: 0', 'Unnamed: 0.1','Neg_Review_Clean', 'Pos_Review_Clean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.to_csv('vader.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.drop('Additional_Number_of_Scoring', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader[vader['pos_sent']<-0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader[vader['neg_sent']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Positive_Review'][577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Hotel_Address'][455551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = data['Hotel_Address']\n",
    "for idx, i in enumerate(city):\n",
    "    if 'Amsterdam' in i:\n",
    "        city[idx] = 'Amsterdam'\n",
    "    if 'Vienna' in i:\n",
    "        city[idx] = 'Vienna'\n",
    "    if 'Milan' in i:\n",
    "        city[idx] = 'Milan'\n",
    "    if 'Barcelona' in i:\n",
    "        city[idx] = 'Barcelona'\n",
    "    if 'Paris' in i:\n",
    "        city[idx] = 'Paris'\n",
    "    if 'London' in i:\n",
    "        city[idx] = 'London'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = pd.Series(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader['City'] = city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.get_dummies(vader['City'])\n",
    "vader = vader.join(cities)\n",
    "vader.drop(['City'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "NB = GaussianNB()\n",
    "neg_pos = data['Reviewer_Score'] > 7.25\n",
    "sentiment_predictor = NB.fit(tfidf_pos, neg_pos)\n",
    "sentiment_predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(data['Reviewer_Score'], bins = 40)\n",
    "plt.xlabel('Reviewer Score')\n",
    "plt.ylabel('Occurrences')\n",
    "plt.title('Frequency Distribution of Reviewer Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Additional_Number_of_Scoring', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['lat', 'lng', 'Total_Number_of_Reviews', 'Total_Number_of_Reviews_Reviewer_Has_Given'], axis=1, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviewer_Score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviewer_Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.395-3*1.637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data['Reviewer_Score']<3\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed = pd.read_csv('lemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed[\"Negative_Review\"] = lemmed[\"Negative_Review\"].apply(lambda x: str(x).replace(\"No Negative\", \"\"))\n",
    "lemmed[\"Positive_Review\"] = lemmed[\"Positive_Review\"].apply(lambda x: str(x).replace(\"No Positive\", \"\"))\n",
    "lemmed[\"Neg_Review_Clean\"] = lemmed[\"Neg_Review_Clean\"].apply(lambda x: str(x).replace(\"No Negative\", \"\"))\n",
    "lemmed[\"Pos_Review_Clean\"] = lemmed[\"Pos_Review_Clean\"].apply(lambda x: str(x).replace(\"No Positive\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed[\"Pos_Review_Clean\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "sp = []\n",
    "for i in lemmed['Pos_Review_Clean']:\n",
    "    misspelled = spell.unknown(word_tokenize(i))\n",
    "    for w in misspelled:\n",
    "        sp.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed['differential'] = lemmed['Reviewer_Score'] - data['Average_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dict = {}\n",
    "for idx, i in enumerate(lemmed['Neg_Review_Clean']):\n",
    "    try:\n",
    "        for w in word_tokenize(i):\n",
    "            if w.isalpha():\n",
    "                w=w.lower()\n",
    "                if w not in neg_dict.keys():\n",
    "                    neg_dict[w] = 0\n",
    "                neg_dict[w] -=1\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(neg_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "for i in lemmed['Pos_Review_Clean']:\n",
    "    try:\n",
    "        for w in word_tokenize(i):\n",
    "            w=w.lower()\n",
    "            if w.isalpha():\n",
    "                if w not in pos_dict.keys():\n",
    "                    pos_dict[w] = 0\n",
    "\n",
    "                pos_dict[w]+=1\n",
    "    except TypeError:\n",
    "        continue            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(pos_dict.values())[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neg_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = neg_dict.copy()\n",
    "\n",
    "for i in pos_dict.keys():\n",
    "    if i not in merged_dict.keys():\n",
    "        merged_dict[i]=0\n",
    "    merged_dict[i] += pos_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neg = sorted(merged_dict.items(), key=(lambda item: item[1]))[:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pos = sorted(merged_dict.items(), key=(lambda item: item[1]))[73480:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_pos[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = analyser.lexicon.keys()\n",
    "b = analyser.lexicon.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_lexicon = {k:v for k,v in zip(a,b)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lexicon = []\n",
    "for i in top_pos:\n",
    "    if i[0] in hotel_lexicon.keys():\n",
    "        in_lexicon.append((i[0], hotel_lexicon[i[0]]))\n",
    "    else:\n",
    "        in_lexicon.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_in_lexicon = [i for i in in_lexicon if i[1]>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin_lexicon = []\n",
    "for i in top_neg:\n",
    "    if i[0] in hotel_lexicon.keys():\n",
    "        nin_lexicon.append((i[0], hotel_lexicon[i[0]]))\n",
    "    else:\n",
    "        nin_lexicon.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_in_lexicon = [i for i in nin_lexicon if i[1]<-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_in_lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pos_in_lexicon = [i[0] for i in pos_in_lexicon]\n",
    "w_neg_in_lexicon = [i[0] for i in neg_in_lexicon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_neg_in_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "#vader3\n",
    "'''pos_words = {'large':1.5,\n",
    " 'minute':1,\n",
    " 'convenient':1.5,\n",
    " 'walking':1,\n",
    " 'near':1,\n",
    " 'central':1,\n",
    " 'view':1,\n",
    " 'walk':1,\n",
    " 'spacious':2,\n",
    " 'modern':2,\n",
    " 'everything':1,\n",
    " 'quiet':1,\n",
    " 'comfy':1,\n",
    " 'close':1,\n",
    " 'location':1.5}\n",
    "\n",
    "neg_words = {\n",
    " 'small': -2,\n",
    " 'little':-2,\n",
    " 'expensive': -2,\n",
    " 'work':-1,\n",
    " 'not':-1,\n",
    " 'air':-0.5,\n",
    " 'noise': -2,\n",
    " 'told':-0.5,\n",
    " 'bathroom':-1,\n",
    " 'water':-1,\n",
    " 'booking': -1,\n",
    " 'hot':-1,\n",
    " 'shower':-2,\n",
    " 'cold': -3,\n",
    " 'price':-1,\n",
    " 'slow': -2,\n",
    " 'booked':-1,\n",
    " 'old':-1,\n",
    " 'paid':-0.5,\n",
    " 'toilet':-1,\n",
    " 'tiny':-2,\n",
    " 'working':-1}\n",
    "'''\n",
    "\n",
    "#vader4\n",
    "pos_words = {'large':1.5,\n",
    " 'minute':1,\n",
    " 'convenient':1.5,\n",
    " 'walking':1,\n",
    " 'near':1,\n",
    " 'central':1,\n",
    " 'view':1,\n",
    " 'walk':1,\n",
    " 'spacious':2,\n",
    " 'modern':2,\n",
    " 'everything':1,\n",
    " 'quiet':1,\n",
    " 'comfy':1,\n",
    " 'close':1,\n",
    " 'location':1.5}\n",
    "\n",
    "neg_words = {\n",
    " 'i':-.05\n",
    " 'small': -2,\n",
    " 'little':-2,\n",
    " 'expensive': -2,\n",
    " 'work':-1,\n",
    " 'not':-1,\n",
    " 'air':-1,\n",
    " 'noise': -2,\n",
    " 'told':-0.5,\n",
    " 'bathroom':-1,\n",
    " 'water':-1,\n",
    " 'booking': -1,\n",
    " 'hot':-1,\n",
    " 'shower':-2,\n",
    " 'cold': -3,\n",
    " 'price':-1,\n",
    " 'slow': -2,\n",
    " 'booked':-1,\n",
    " 'old':-1,\n",
    " 'paid':-0.5,\n",
    " 'toilet':-1,\n",
    " 'tiny':-2,\n",
    " 'working':-1}\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "analyser.lexicon.update(pos_words)\n",
    "analyser.lexicon.update(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = pd.read_csv('vader.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Negative_Review\"] = data[\"Negative_Review\"].apply(lambda x: str(x).replace(\"No Negative\", \"\"))\n",
    "data[\"Positive_Review\"] = data[\"Positive_Review\"].apply(lambda x: str(x).replace(\"No Positive\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = data['Positive_Review']\n",
    "pos_review_sentiment = []\n",
    "for i in pos:\n",
    "    snt = analyser.polarity_scores(i)\n",
    "    pos_review_sentiment.append(snt['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = data['Negative_Review']\n",
    "neg_review_sentiment = []\n",
    "for i in neg:\n",
    "    snt = analyser.polarity_scores(i)\n",
    "    neg_review_sentiment.append(snt['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3 = vader2.copy()\n",
    "vader3['new_pos_sent'] = pos_review_sentiment\n",
    "vader3['New_neg_sent'] = neg_review_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader3.to_csv('vader3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader2.to_csv('vader2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader2 = pd.read_csv('vader2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader2.drop(['pos_sent', 'neg_sent'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = vader3.pop('Reviewer_Score')\n",
    "#Xv2 = vader3\n",
    "Xv2_train, Xv2_test, yv2_train, yv2_test = train_test_split(Xv,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=20, max_features=15, min_samples_leaf=10,\n",
    "                      n_estimators=500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8644864926810877 vader, vader2: 0.8652860490218461, v3: 0.8591603772526949\n",
    "\n",
    "rf.fit(Xv_train, yv2_train)\n",
    "\n",
    "yvadersearch = rf.predict(Xv2_test)\n",
    "mean_absolute_error(yv2_test, yvadersearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=50, max_features=70, min_samples_leaf=30,\n",
    "                      n_estimators=500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(Xv_train, yv_train)\n",
    "\n",
    "yvadersearch = rf.predict(Xv_test)\n",
    "mean_absolute_error(yv_test, yvadersearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = (yvadersearch-yv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(yv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.mean(difference)})\n",
    "print(min(difference)) #max overguess\n",
    "print(max(difference)) # max underguess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(yv_test,resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edited_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(edited_dict.items(), key=(lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = {key:val for key, val in merged_dict.items() if key in edited_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Negative_Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hotel_Sentiment_Analyzer:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    '''Hotel Sentiment Analyzer class\n",
    "    Fit takes in X an array of reviews as strings '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(max_features=2000, stop_words='english')\n",
    "        tfidf_pos = count.fit_transform(pos_content.values.astype('U'))\n",
    "        tfidf_neg = count.fit_transform(neg_content.values.astype('U'))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [('Location', 182356),\n",
    " ('Staff', 156235),\n",
    " ('Good', 91507),\n",
    " ('Friendly', 80715),\n",
    " ('Helpful', 71799),\n",
    " ('Excellent', 59915),\n",
    " ('Nice', 59561),\n",
    " ('Clean', 58436),\n",
    " ('Comfortable', 54418),\n",
    " ('Hotel', 49731)]\n",
    "words = []\n",
    "vals = []\n",
    "for i in lst:\n",
    "    words.append(i[0])\n",
    "    vals.append(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = pd.DataFrame([words,vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words=pos_words.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.bar(pos_words[0], pos_words[1])\n",
    "ax.xaxis.set_tick_params(labelsize=16, rotation=45, )\n",
    "ax.set_xlabel('Positive Words')\n",
    "ax.set_ylabel('Relative Occurrences')\n",
    "fig.suptitle('Top 10 Positive Words Relative Occurrences', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglst = [ \n",
    "('I', 54831),\n",
    " ('Small', 38226),\n",
    " ('Nothing', 32126),\n",
    " ('Room', 29869),\n",
    " ('Bit', 23675),\n",
    " ('Could', 22721),\n",
    " ('Poor', 15300),\n",
    " ('Little', 15107),\n",
    " ('Expensive', 14225),\n",
    " ('Noisy', 12803)\n",
    "]\n",
    "words = []\n",
    "vals = []\n",
    "for i in neglst:\n",
    "    words.append(i[0])\n",
    "    vals.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = pd.DataFrame([words,vals])\n",
    "neg_words=neg_words.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.bar(neg_words[0], neg_words[1])\n",
    "ax.xaxis.set_tick_params(labelsize=16, rotation=45)\n",
    "ax.set_xlabel('Negative Words')\n",
    "ax.set_ylabel('Relative Occurrences')\n",
    "fig.suptitle('Top 10 Negative Words Relative Occurrences', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist = [('fabulous', 0.29964397592170217), ('room', 0.30194291249199645), ('Review_Total_Positive_Word_Counts', 0.3052570176688559), ('view_neg', 0.3065943580036194), ('customer_neg', 0.309148504285848), ('like', 0.3097000750242623), ('cleaned_neg', 0.3138296421587767), ('far_neg', 0.31415213928598024), ('experience_neg', 0.3160898314851383), ('upgraded', 0.31808503933448273), ('uncomfortable_neg', 0.3181067243519525), ('amazing', 0.32032346693149794), ('positive', 0.3268533664683133), ('friendly_neg', 0.3279204781542303), ('star', 0.3316088215976614), ('money', 0.33323600792235114), ('furniture_neg', 0.33556941761333337), ('thing_neg', 0.3359991773269183), ('basic_neg', 0.3371390389734257), ('worth_neg', 0.34183704961622896), ('bad_neg', 0.35738071688622886), ('excellent', 0.3594808207557529), ('service', 0.359927338350747), ('good', 0.36450212979652796), ('value_neg', 0.36939321877731096), ('Average_Score', 0.37155553164158), ('maybe_neg', 0.3742655712045161), ('slightly_neg', 0.3756614262933333), ('problem_neg', 0.37852534112012903), ('negative_neg', 0.3795259726073531), ('liked_neg', 0.3798875420290196), ('loved', 0.38373564215679484), (' Leisure trip ', 0.3845988736897397), ('thing', 0.3854006269861976), ('tiny_neg', 0.3855309579764056), ('smell_neg', 0.39104875876111), ('comfort', 0.396663971459846), ('service_neg', 0.40567563202398277), ('poor_neg', 0.40716188873969195), ('location', 0.4366442383734017), ('exceptional', 0.44605379501967746), ('fantastic', 0.4506617635248613), ('manager_neg', 0.4539769613296106), ('dated_neg', 0.4552046506772193), ('little_neg', 0.4669997007938732), ('bed_neg', 0.48724146197141455), ('location_neg', 0.5196409792334291), ('terrible_neg', 0.5253355840173783), ('ok', 0.533507276280509), ('old_neg', 0.5588221246639997), ('rude_neg', 0.5628752955510673), ('bit_neg', 0.5665008095155175), ('overpriced_neg', 0.5972159823682486), ('staff', 0.6016395407762328), ('hotel_neg', 0.6126645258793607), ('clean_neg', 0.6272994880442819), ('rooms_neg', 0.6394214532205174), ('Review_Total_Negative_Word_Counts', 0.643662427137203), ('star_neg', 0.6624058946175011), ('money_neg', 0.6654582424585267), ('cleanliness', 0.702056108507394), ('perfect_neg', 0.7507870704583097), ('fault_neg', 0.7786412114249133), ('dirty_neg', 0.9736228654579733), ('staff_neg', 1.1175715739400547), ('new_pos_sent', 1.197688207777768), ('New_neg_sent', 1.3588873831895074), ('room_neg', 3.213848362698663)][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

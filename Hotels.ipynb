{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from: https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Hotel_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "3                                           1             3.8   \n",
       "4                                           3             6.7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  \n",
       "3  52.360576  4.915968  \n",
       "4  52.360576  4.915968  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515738 entries, 0 to 515737\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   Hotel_Address                               515738 non-null  object \n",
      " 1   Additional_Number_of_Scoring                515738 non-null  int64  \n",
      " 2   Review_Date                                 515738 non-null  object \n",
      " 3   Average_Score                               515738 non-null  float64\n",
      " 4   Hotel_Name                                  515738 non-null  object \n",
      " 5   Reviewer_Nationality                        515738 non-null  object \n",
      " 6   Negative_Review                             515738 non-null  object \n",
      " 7   Review_Total_Negative_Word_Counts           515738 non-null  int64  \n",
      " 8   Total_Number_of_Reviews                     515738 non-null  int64  \n",
      " 9   Positive_Review                             515738 non-null  object \n",
      " 10  Review_Total_Positive_Word_Counts           515738 non-null  int64  \n",
      " 11  Total_Number_of_Reviews_Reviewer_Has_Given  515738 non-null  int64  \n",
      " 12  Reviewer_Score                              515738 non-null  float64\n",
      " 13  Tags                                        515738 non-null  object \n",
      " 14  days_since_review                           515738 non-null  object \n",
      " 15  lat                                         512470 non-null  float64\n",
      " 16  lng                                         512470 non-null  float64\n",
      "dtypes: float64(4), int64(5), object(8)\n",
      "memory usage: 66.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel_Address 1493\n",
      "Additional_Number_of_Scoring 480\n",
      "Review_Date 731\n",
      "Average_Score 34\n",
      "Hotel_Name 1492\n",
      "Reviewer_Nationality 227\n",
      "Negative_Review 330011\n",
      "Review_Total_Negative_Word_Counts 402\n",
      "Total_Number_of_Reviews 1142\n",
      "Positive_Review 412601\n",
      "Review_Total_Positive_Word_Counts 365\n",
      "Total_Number_of_Reviews_Reviewer_Has_Given 198\n",
      "Reviewer_Score 37\n",
      "Tags 55242\n",
      "days_since_review 731\n",
      "lat 1473\n",
      "lng 1473\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(i, len(data[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with no review\n",
    "data = data[(data['Negative_Review'] != 'No Negative') | (data['Positive_Review'] != 'No Positive')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Hotel_Name', axis=1, inplace=True)\n",
    "data['Average_Score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark - error if you always guessed the average\n",
    "mean_absolute_error(data['Average_Score'], data['Reviewer_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = data.Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "new_tags = []\n",
    "for i in tags:\n",
    "    new_tags.append(ast.literal_eval(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check most common tags\n",
    "from collections import Counter\n",
    "list_for_counting = []\n",
    "for i in new_tags:\n",
    "    for t in i:\n",
    "        list_for_counting.append(t)\n",
    "    \n",
    "c = Counter(list_for_counting)\n",
    "c.most_common(20)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering tags to reduce columns\n",
    "for index, i in enumerate(new_tags):\n",
    "    for idx, t in enumerate(i):\n",
    "        if t in [' Stayed 1 night ',' Stayed 2 nights ']:\n",
    "            new_tags[index][idx] = 'Stayed 1-2 nights'\n",
    "        if t in [' Stayed 3 nights ',' Stayed 4 nights ']:\n",
    "            new_tags[index][idx] = 'Stayed 3-4 nights'\n",
    "        if t in [' Stayed 5 nights ',' Stayed 6 nights ', ' Stayed 7 nights ', ' Stayed 8 nights ', ' Stayed 9 nights ', ' Stayed 10 nights ',  ' Stayed 11 nights ',\n",
    "             ' Stayed 12 nights ', ' Stayed 13 nights ', ' Stayed 14 nights ', ' Stayed 15 nights ', ' Stayed 16 nights ', ' Stayed 17 nights ',' Stayed 18 nights ', ' Stayed 19 nights ', ' Stayed 20 nights ',\n",
    "             ' Stayed 21 nights ', ' Stayed 22 nights ', ' Stayed 23 nights ', ' Stayed 24 nights ', ' Stayed 25 nights ', ' Stayed 26 nights ',\n",
    "             ' Stayed 27 nights ', ' Stayed 28 nights ', ' Stayed 29 nights ', ' Stayed 30 nights ', ' Stayed 31 nights ',]:\n",
    "            new_tags[index][idx] = 'Stayed 5+ nights'\n",
    "        if 'Apartment' in t or 'Apartement' in t:\n",
    "            new_tags[index][idx] = 'Apartment'\n",
    "        if 'Luxury' in t or 'VIP' in t or 'Executive' in t or 'Ambassador' in t or 'Royal' in t or 'Penthouse' in t or 'Suite' in t:\n",
    "            new_tags[index][idx] = 'Fancy'\n",
    "        if 'Standard' in t or 'Budget' in t or 'Small' in t or 'Economy' in t or 'Basic' in t or 'Bunk Bed' in t or 'Interior' in t or 'Special Offer' in t:\n",
    "            new_tags[index][idx] = 'Budget'\n",
    "        if 'Comfort' in t or 'Family' in t or 'Classic' in t or 'Large' in t:\n",
    "            new_tags[index][idx] = 'Medium'\n",
    "        if 'Superior' in t or 'Premium' in t or 'Prestige' in t or 'Premiere' in t or 'Privilege' in t or 'Deluxe' in t or 'Premier' in t or 'Club' in t:\n",
    "            new_tags[index][idx] = 'High'\n",
    "tags_final = []\n",
    "for index, i in enumerate(new_tags):\n",
    "    new = []\n",
    "    for idx, t in enumerate(i):\n",
    "        if t in ['Stayed 1-2 nights','Stayed 3-4 nights', 'Suite', 'Apartment', 'Fancy', 'Budget', 'Medium', 'High', ' Business Trip ', ' Solo Traveler ', ' Leisure trip ', ' Couple ', ' Group ', ' Family with young children ', ' Family with older children ']:\n",
    "            new.append(i[idx])\n",
    "    tags_final.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = []\n",
    "for i in tags_final:\n",
    "    for t in i:\n",
    "        if t not in unique_tags:\n",
    "            unique_tags.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['New_Tags'] = tags_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "tagdf = pd.DataFrame(mlb.fit_transform(data.New_Tags),columns=mlb.classes_, index=data.index)\n",
    "\n",
    "\n",
    "data = data.join(tagdf)\n",
    "data = data.drop(['New_Tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn object into in\n",
    "data['days_since_review'] = data['days_since_review'].apply(lambda x: int(x.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Hotel_Address', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Tags', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = data.pop('Negative_Review')\n",
    "pos = data.pop('Positive_Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = pd.get_dummies(data['Reviewer_Nationality'], prefix='Nationality: ')\n",
    "data = data.join(nat)\n",
    "data = data.drop(['Reviewer_Nationality'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Review_Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = data.pop('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng = data.pop('lng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_review_sentiment = []\n",
    "for i in neg:\n",
    "    review = TextBlob(i)\n",
    "    neg_review_sentiment.append(review.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_review_sentiments = [i[0] for i in neg_review_sentiment]\n",
    "data['neg_review_sentiment'] = neg_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_sentiment = []\n",
    "for i in pos:\n",
    "    review = TextBlob(i)\n",
    "    pos_review_sentiment.append(review.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_sentiments = [i[0] for i in pos_review_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean['pos_review_sentiment'] = pos_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean.to_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>...</th>\n",
       "      <th>Nationality: _ Vanuatu</th>\n",
       "      <th>Nationality: _ Vatican City</th>\n",
       "      <th>Nationality: _ Venezuela</th>\n",
       "      <th>Nationality: _ Vietnam</th>\n",
       "      <th>Nationality: _ Wallis and Futuna</th>\n",
       "      <th>Nationality: _ Yemen</th>\n",
       "      <th>Nationality: _ Zambia</th>\n",
       "      <th>Nationality: _ Zimbabwe</th>\n",
       "      <th>neg_review_sentiment</th>\n",
       "      <th>pos_review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>7.7</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.241960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>7.7</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>7.7</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070370</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>7.7</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515606</th>\n",
       "      <td>515606</td>\n",
       "      <td>515733</td>\n",
       "      <td>168</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14</td>\n",
       "      <td>2823</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>704</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515607</th>\n",
       "      <td>515607</td>\n",
       "      <td>515734</td>\n",
       "      <td>168</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2823</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>5.8</td>\n",
       "      <td>712</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515608</th>\n",
       "      <td>515608</td>\n",
       "      <td>515735</td>\n",
       "      <td>168</td>\n",
       "      <td>8.1</td>\n",
       "      <td>19</td>\n",
       "      <td>2823</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.113636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515609</th>\n",
       "      <td>515609</td>\n",
       "      <td>515736</td>\n",
       "      <td>168</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2823</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515610</th>\n",
       "      <td>515610</td>\n",
       "      <td>515737</td>\n",
       "      <td>168</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13</td>\n",
       "      <td>2823</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>725</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515611 rows Ã— 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Additional_Number_of_Scoring  Average_Score  \\\n",
       "0                0             0                           194            7.7   \n",
       "1                1             1                           194            7.7   \n",
       "2                2             2                           194            7.7   \n",
       "3                3             3                           194            7.7   \n",
       "4                4             4                           194            7.7   \n",
       "...            ...           ...                           ...            ...   \n",
       "515606      515606        515733                           168            8.1   \n",
       "515607      515607        515734                           168            8.1   \n",
       "515608      515608        515735                           168            8.1   \n",
       "515609      515609        515736                           168            8.1   \n",
       "515610      515610        515737                           168            8.1   \n",
       "\n",
       "        Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                     397                     1403   \n",
       "1                                       0                     1403   \n",
       "2                                      42                     1403   \n",
       "3                                     210                     1403   \n",
       "4                                     140                     1403   \n",
       "...                                   ...                      ...   \n",
       "515606                                 14                     2823   \n",
       "515607                                 11                     2823   \n",
       "515608                                 19                     2823   \n",
       "515609                                  0                     2823   \n",
       "515610                                 13                     2823   \n",
       "\n",
       "        Review_Total_Positive_Word_Counts  \\\n",
       "0                                      11   \n",
       "1                                     105   \n",
       "2                                      21   \n",
       "3                                      26   \n",
       "4                                       8   \n",
       "...                                   ...   \n",
       "515606                                  2   \n",
       "515607                                 11   \n",
       "515608                                  0   \n",
       "515609                                 25   \n",
       "515610                                  6   \n",
       "\n",
       "        Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                                7             2.9   \n",
       "1                                                7             7.5   \n",
       "2                                                9             7.1   \n",
       "3                                                1             3.8   \n",
       "4                                                3             6.7   \n",
       "...                                            ...             ...   \n",
       "515606                                           8             7.0   \n",
       "515607                                          12             5.8   \n",
       "515608                                           3             2.5   \n",
       "515609                                           3             8.8   \n",
       "515610                                           1             8.3   \n",
       "\n",
       "        days_since_review  ...  Nationality: _ Vanuatu   \\\n",
       "0                       0  ...                        0   \n",
       "1                       0  ...                        0   \n",
       "2                       3  ...                        0   \n",
       "3                       3  ...                        0   \n",
       "4                      10  ...                        0   \n",
       "...                   ...  ...                      ...   \n",
       "515606                704  ...                        0   \n",
       "515607                712  ...                        0   \n",
       "515608                715  ...                        0   \n",
       "515609                717  ...                        0   \n",
       "515610                725  ...                        0   \n",
       "\n",
       "        Nationality: _ Vatican City   Nationality: _ Venezuela   \\\n",
       "0                                  0                          0   \n",
       "1                                  0                          0   \n",
       "2                                  0                          0   \n",
       "3                                  0                          0   \n",
       "4                                  0                          0   \n",
       "...                              ...                        ...   \n",
       "515606                             0                          0   \n",
       "515607                             0                          0   \n",
       "515608                             0                          0   \n",
       "515609                             0                          0   \n",
       "515610                             0                          0   \n",
       "\n",
       "        Nationality: _ Vietnam   Nationality: _ Wallis and Futuna   \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "...                         ...                                ...   \n",
       "515606                        0                                  0   \n",
       "515607                        0                                  0   \n",
       "515608                        0                                  0   \n",
       "515609                        0                                  0   \n",
       "515610                        0                                  0   \n",
       "\n",
       "        Nationality: _ Yemen   Nationality: _ Zambia   \\\n",
       "0                           0                       0   \n",
       "1                           0                       0   \n",
       "2                           0                       0   \n",
       "3                           0                       0   \n",
       "4                           0                       0   \n",
       "...                       ...                     ...   \n",
       "515606                      0                       0   \n",
       "515607                      0                       0   \n",
       "515608                      0                       0   \n",
       "515609                      0                       0   \n",
       "515610                      0                       0   \n",
       "\n",
       "        Nationality: _ Zimbabwe   neg_review_sentiment  pos_review_sentiment  \n",
       "0                              0              0.028671              0.283333  \n",
       "1                              0              0.150000              0.241960  \n",
       "2                              0              0.032653              0.460000  \n",
       "3                              0             -0.070370              0.625000  \n",
       "4                              0             -0.009091              0.300000  \n",
       "...                          ...                   ...                   ...  \n",
       "515606                         0              0.000000              0.000000  \n",
       "515607                         0             -0.250000              0.250000  \n",
       "515608                         0              0.100000             -0.113636  \n",
       "515609                         0              0.150000              0.300000  \n",
       "515610                         0              0.200000              0.780000  \n",
       "\n",
       "[515611 rows x 249 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('Reviewer_Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(min_samples_leaf = 30,\n",
    "                          max_depth=25,\n",
    "                          max_features=10,\n",
    "                          n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr = GradientBoostingRegressor(learning_rate=0.01,\n",
    "                                  loss='ls',\n",
    "                                 max_depth=15,\n",
    "                                  n_estimators=100,\n",
    "                                 min_samples_leaf=120,\n",
    "                                 max_features=10,\n",
    "                                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = gdbr.predict(X_test)\n",
    "mean_absolute_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "param_dist = dict(min_samples_leaf = [5,10,15,20,30,50],\n",
    "                          max_depth = [5,10,15,20,25,30],\n",
    "                          max_features=[10, 20, 30, 40, 50],\n",
    "                          n_estimators=[50,75,100,300,500,1000])\n",
    "rand2 = RandomizedSearchCV(rf, param_dist, cv=10, scoring='neg_mean_absolute_error', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "pprint(rand2.best_estimator_.get_params())\n",
    "\n",
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'mse',\n",
    " 'max_depth': 30,\n",
    " 'max_features': 40,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 500,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Best random forest results\n",
    "RandomizedSearchCV(cv=10, error_score=nan,\n",
    "                   estimator=RandomForestRegressor(bootstrap=True,\n",
    "                                                   ccp_alpha=0.0,\n",
    "                                                   criterion='mse',\n",
    "                                                   max_depth=25,\n",
    "                                                   max_features=10,\n",
    "                                                   max_leaf_nodes=None,\n",
    "                                                   max_samples=None,\n",
    "                                                   min_impurity_decrease=0.0,\n",
    "                                                   min_impurity_split=None,\n",
    "                                                   min_samples_leaf=30,\n",
    "                                                   min_samples_split=2,\n",
    "                                                   min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=500,\n",
    "                                                   n_jobs=None, oob_score=False,\n",
    "                                                   ra...rbose=0,\n",
    "                                                   warm_start=False),\n",
    "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
    "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
    "                                        'max_features': [10, 20, 30, 40, 50],\n",
    "                                        'min_samples_leaf': [5, 10, 15, 20, 30,\n",
    "                                                             50],\n",
    "                                        'n_estimators': [50, 75, 100, 300, 500,\n",
    "                                                         1000]},\n",
    "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrand2 = rand2.predict(X_test)\n",
    "mean_absolute_error(y_test, yrand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbr = GradientBoostingRegressor()\n",
    "param_dist = dict(min_samples_leaf = [10,15,20,30,50],\n",
    "                          max_depth = [5,10,20,30],\n",
    "                          max_features=[10, 20, 30, 40],\n",
    "                          n_estimators=[50,100,300,500],\n",
    "                         learning_rate = [0.1, .05, 0.07, 0.01])\n",
    "booster2 = RandomizedSearchCV(gdbr, param_dist, cv=10, scoring='neg_mean_absolute_error', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n...\n",
       "                                                       warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.05, 0.07,\n",
       "                                                          0.01],\n",
       "                                        'max_depth': [5, 10, 20, 30],\n",
       "                                        'max_features': [10, 20, 30, 40],\n",
       "                                        'min_samples_leaf': [10, 15, 20, 30,\n",
       "                                                             50],\n",
       "                                        'n_estimators': [50, 100, 300, 500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV(cv=10, error_score=nan,\n",
    "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
    "                                                       criterion='friedman_mse',\n",
    "                                                       init=None,\n",
    "                                                       learning_rate=0.01,\n",
    "                                                       loss='ls', max_depth=15,\n",
    "                                                       max_features=10,\n",
    "                                                       max_leaf_nodes=None,\n",
    "                                                       min_impurity_decrease=0.0,\n",
    "                                                       min_impurity_split=None,\n",
    "                                                       min_samples_leaf=120,\n",
    "                                                       min_samples_split=2,\n",
    "                                                       min_weight_fraction_leaf=0.0,\n",
    "                                                       n_estimators=100...\n",
    "                                                       warm_start=False),\n",
    "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
    "                   param_distributions={'learning_rate': [0.1, 0.05, 0.07,\n",
    "                                                          0.01],\n",
    "                                        'max_depth': [5, 10, 20, 30],\n",
    "                                        'max_features': [10, 20, 30, 40],\n",
    "                                        'min_samples_leaf': [10, 15, 20, 30,\n",
    "                                                             50],\n",
    "                                        'n_estimators': [50, 100, 300, 500,\n",
    "                                                         1000]},\n",
    "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
    "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07593062281089308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yboost2 = booster2.predict(X_test)\n",
    "mean_absolute_error(y_test, yboost2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Best gradient boost score\n",
    "from pprint import pprint\n",
    "pprint(booster2.best_estimator_.get_params())\n",
    "{'alpha': 0.9,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'friedman_mse',\n",
    " 'init': None,\n",
    " 'learning_rate': 0.1,\n",
    " 'loss': 'ls',\n",
    " 'max_depth': 30,\n",
    " 'max_features': 40,\n",
    " 'max_leaf_nodes': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 50,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_iter_no_change': None,\n",
    " 'presort': 'deprecated',\n",
    " 'random_state': None,\n",
    " 'subsample': 1.0,\n",
    " 'tol': 0.0001,\n",
    " 'validation_fraction': 0.1,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X_train, pos_X_test, pos_y_train, pos_y_test = train_test_split(pos,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(pos_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.9,  7.5,  7.1,  3.8,  6.7,  4.6, 10. ,  6.5,  7.9,  5.8,  9.2,\n",
       "        8.8,  6.3,  5.4,  9.6,  8.3,  4.2,  3.3,  5. ,  2.5,  3.1,  6. ,\n",
       "        5.5,  9.5,  8. ,  8.5,  9. ,  4.5,  7. ,  5.6,  8.1,  6.9,  9.4,\n",
       "        3. ,  4. ,  3.5,  4.4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    515611.000000\n",
       "mean          8.395103\n",
       "std           1.637852\n",
       "min           2.500000\n",
       "25%           7.500000\n",
       "50%           8.800000\n",
       "75%           9.600000\n",
       "max          10.000000\n",
       "Name: Reviewer_Score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "for i, j in zip(data.lat, data.lng):\n",
    "    coordinates.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(coordinates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "m = folium.Map(location=[52.360576, 4.915968])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(coordinates[0])):\n",
    "    folium.Marker(coordinates[0], popup=df_counters['Name'][point]).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
